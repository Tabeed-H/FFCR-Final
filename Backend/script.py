'''
Authors: @tabeed @hammad @fatimah
scripyt.py is the main python script that is response for the face detection and recognition.
The model was first trained on Google Collab and then tested.
The script can recognise more than one face at a time but is tailored to return only one.
'''

'''
Import required dependancies
'''
import cv2                    # OpenCV library to work with iamges
import numpy as np            # To work with multi-dimensional arrays
import dlib                   # Requirement for face_recognition library
import pickle                 # To open the encodings and names stored in pickle file
import imutils                # To resize input image
import face_recognition       # Deep Learning model for recognition


'''
Uncomment for model evaluation
'''
# FOR STAND-ALONE RUN
# import os                   # Uncomment this line when to testing the script

'''
Open pickle file
  _description_
  To open the pickle file that contains the encodings and the names.
  This pickle file was generated by training the model on the custom dataset.
  The pickle file stores two structures:
    'Encodings': Encoding for each face.
    'Names'    : Name of all files encoded.
'''
pickle_name = './face_encodings_FFCR.pickle'                    # Path to pickle file
data_encoding = pickle.loads(open(pickle_name, "rb").read())    # Open pickle file
list_encodings = data_encoding["encodings"]                     # Destructure pickle file and extract encodings 
list_names = data_encoding["names"]                             # Destructure pickle file and extract names


'''
Funtion: recognize_faces
-------------------------
The recognize_faces function takes an input image and attempts to recognize and identify faces within the image using a provided list of known face encodings and names.

Parameters
--------------

image 
  _type_
  numpy.ndarray

  _descriptions_
  The input image in which faces are to be recognized. This should be a color image in RGB format.

list_encodings 
  _type_
  list 
  
  _description_
  A list of known face encodings. Each encoding is a list or array representing a known face.

list_names 
  _type_
  list
  
  _description_
  A list of names corresponding to the face encodings in list_encodings. Each name should be a string.

tolerance 
  _type_
  float, optional
  
  _description_
  The tolerance level for face matching. Lower values make the function more strict in matching faces. Default value is 0.6.


Returns
--------

face_locations 
  _type_
  numpy.ndarray
  
  _description_
  An array of face locations in the image. Each face location is represented as a list of four integers: [top, right, bottom, left].

face_names
  _type_
  list
  
  _description_
  A list of names corresponding to the recognized faces in the image. If a face is not identified, the name will be 'Not identified'.

conf_values 
  _type_
  list
  
  _description_
  A list of confidence values for each recognized face. The confidence value is the distance between the face encoding and the closest known face encoding. Lower values indicate a better match.

error
  _type_
  string

  _description_
  If an occur is encounterd the error is set to a corresponding error string. None by default
'''
def recognize_faces(image, list_encodings, list_names, tolerance = 0.6):
  error = None    # To store the error string if any                                    
  img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # convert image color to RGB format

  # FACE DETECTION
  #------------------
  # 'face_locations' is a list of face location detected in the image.
  # Requires the original image only
  face_locations = face_recognition.face_locations(img_rgb)   # function of face_recognition model to locate the faces (used HOG)
  # For error handling: If no face is detected
  if len(face_locations) == 0:
     error = 'Detection Error: No Face Detected!'
     return None, None, None, error   # Set other return values to None and only error should be returned
  
  # GENERATE FACE ENCODING
  #------------------------
  # 'face_encoding' is a list of face encoding detected in the image
  # Requires the orginal image and face_locations
  face_encodings = face_recognition.face_encodings(img_rgb, face_locations)
  # For error handling: If encoding is not generated
  if len(face_encodings) == 0:
     error = 'Detection Error: Cannot create encodings for the face uploaded'
     return None, None, None, error   # Set other return values to None and only error should be returned
  
  # RECOGNITION
  #--------------
  face_names = []   # Store names of detected faces
  conf_values = []  # Store confidence values of detected faces

  # Loop iterate over each 'encoding' in 'face_encodings'
  for encoding in face_encodings:
    # Compare the current face encodings with all know encodings.
    matches = face_recognition.compare_faces(list_encodings, encoding, tolerance = tolerance)

    # Initialze the name as 'Not identified' for the current face encoding
    name = 'Not identified'

    # Calculte the distance between the current face encoding and all know encodings
    # Smaller disctance indicate higher similarity
    face_distances = face_recognition.face_distance(list_encodings, encoding)

    # Find the index of the closet match ie, the smallest distance
    best_match_index = np.argmin(face_distances)

    # If the closet match is within the tolerance, set the identified name
    if matches[best_match_index]:
      name = list_names[best_match_index]

    # Append the identified name and confidence value to the respective lists
    face_names.append(name)
    conf_values.append(face_distances[best_match_index])

  # Convert face_loactions to a numpy array and ensure integer type
  face_locations = np.array(face_locations)
  return face_locations.astype(int), face_names, conf_values, error

'''
Function: show_recognition
--------------------------
Recognizes faces in an image, draws rectangles around recognized faces, labels them with names, and resizes the image for display.

Parameters
-----------

test_image
  _type_
  numpy.ndarray 
  _description_
  The input image in which faces are to be recognized.

list_encodings
  _type_
  list
  _description_
  A list of known face encodings.

list_names
  _type_
  list
  _description_
  A list of names corresponding to the face encodings in list_encodings.

max_width (optional)
  _type_
  int
  _description_
  The maximum width for the displayed image. Default value is 700.
  
tolerance (optional)
  _type_
  float
  _description_
  The tolerance level for face matching. Default value is 0.6.

Returns
-------

name
  _description_
  Name of the recognised image.
confidence
  _description_
  Confidence Value
'''
def show_recognition(test_image, list_encodings, list_names, max_width=700, tolerance=0.55, test_filename=""):
  # Destructuring return values
  face_locations, face_names, conf_values, error = recognize_faces(test_image, list_encodings, list_names, tolerance)

  # Error Handling: if any error has been encountered in the recognise_faces function
  if error is not None:
    return None, None, error    # Set other return values to None, only return error message

  # DRAW RECTANGLE
  # NOT FOR API CALL
  # ONLY WHEN RUNNING SCRIPT STAND-ALONE
  # Loops through the detected faces, its corresponding names and confidence values
  for face_loc, name, conf in zip(face_locations, face_names, conf_values):
    y1, x2, y2, x1 = face_loc[0], face_loc[1], face_loc[2], face_loc[3]   # Co-ordinated for rectangle
    cv2.putText(test_image, name, (x1, y1 - 10), cv2.FONT_HERSHEY_DUPLEX, 0.8, (0, 0, 255), 2)  # Display name over box
    cv2.rectangle(test_image, (x1, y1), (x2, y2), (0, 10, 255), 4)    # Draw rectangle

    # FOR STAND-ALONE RUN
    # print(f"{test_filename} was recognized as {name}")    # Uncomment when testing script

  # NOT FOR API
  # Resize the image
  if test_image.shape[1] > max_width:
    test_image = imutils.resize(test_image, width=max_width)

    # FOR STAND-ALONE RUN
    # Uncomment below code lines when testing the script
    # cv2.imshow('Recognition',test_image)
    # cv2.waitKey(0)

  return name, conf_values[0], error

'''
Function: test_single_image
---------------------------
To test one image for recognition

Parameters
----------

image_path
  _description_
  Path to the iamg file that you want to test

list_encodings
  _description_
  List of known face encodings used for recognition

'list_names'
  _description_
  List of names correspondiing to the know face encodings

'tolerance'
  _description_
  Tolerance level for face matchin. Default is 0.6

Returns
-------
name
  _description_
  Name of the recognised image

conf
  _description_
  Confidence score of the recognition

error
  _description_
  Error message is any.
'''
def test_single_image(image_path, list_encodings, list_names, max_width=700, tolerance=0.55):
    image_path = str(image_path)    # Convert path to string
    image = cv2.imread(image_path)  # Read image

    # Run Recognition
    name, conf, error = show_recognition(image, list_encodings, list_names, max_width, tolerance)
    if conf >= tolerance:
      error = 'Cannot Recognise: Excedes Recognition Tolerance'
      return None, conf, error

    # Return Values
    return name, conf, error

def recognise_image(image_path):
  print(f"Type of image_path: {type(image_path)}")  # Debugging line
  name, conf, error = test_single_image(image_path, list_encodings, list_names)

  if error is not None:
   return None, conf, error
  

  return name, conf, error

# ---------------------------------------- TESTING MODEL -------------------------------------------------------------
# def test_all_images_in_directory(test_dir, list_encodings, list_names, max_width=700, tolerance=0.6):
#     for filename in os.listdir(test_dir):
#         if filename.endswith(('.jpg', '.jpeg', '.png')):
#             filepath = os.path.join(test_dir, filename)
#             image = cv2.imread(filepath)
#             show_recognition( image, list_encodings, list_names, max_width, tolerance, filename)


# test_image = './DataSet/Test/person01.jpg'
# test_single_image(test_image, list_encodings, list_names)
